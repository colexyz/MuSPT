{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9331738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61261955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 设置中文字体（可选）\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置中文字体（黑体）\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d57030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# 1. 数据处理 —— 数据集 A（原始数据，用于训练模型）\n",
    "#-------------------------------------------------\n",
    "file_path_A = \"Data/Study1_data.csv\" #424个被试\n",
    "df_A = pd.read_csv(file_path_A)\n",
    "# 人格问卷数据\n",
    "cbf_df_A = df_A.copy()\n",
    "# 音乐评分原始\n",
    "rating_cols = [\n",
    "    \"您对音频A的感受评价是？\", \"您对音频B的感受评价是？\", \"您对音频C的感受评价是？\",\n",
    "    \"您对音频D的感受评价是？\", \"您对音频E的感受评价是？\",\n",
    "    \"您对音频F的感受评价是？\", \"您对音频G的感受评价是？\", \"您对音频H的感受评价是？\",\n",
    "    \"您对音频I的感受评价是？\", \"您对音频J的感受评价是？\",\n",
    "    \"您对音频K的感受评价是？\", \"您对音频L的感受评价是？\", \"您对音频M的感受评价是？\",\n",
    "    \"您对音频N的感受评价是？\", \"您对音频O的感受评价是？\",\n",
    "    \"您对音频P的感受评价是？\", \"您对音频Q的感受评价是？\", \"您对音频R的感受评价是？\",\n",
    "    \"您对音频S的感受评价是？\", \"您对音频T的感受评价是？\",\n",
    "    \"您对音频U的感受评价是？\", \"您对音频V的感受评价是？\", \"您对音频W的感受评价是？\",\n",
    "    \"您对音频X的感受评价是？\", \"您对音频Y的感受评价是？\"\n",
    "]\n",
    "ratings_raw_A = df_A[rating_cols].values.astype(np.float32)\n",
    "ratings_converted_A = ratings_raw_A - 4.0  # 转至 [-3,3]\n",
    "# ----------------------------------\n",
    "# 人格问卷反向计分 & 维度计算\n",
    "# ----------------------------------\n",
    "cbf_pi_b_columns = { \"神经质\": [\n",
    "        \"我常感到害怕\",\n",
    "        \"有时我觉得自己一无是处\",\n",
    "        \"别人一句漫不经心的话，我常会联系在自己身上\",\n",
    "        \"在面对压力时，我有种快要崩溃的感觉\",\n",
    "        \"我常担忧一些无关紧要的事情\",\n",
    "        \"我常常感到内心不踏实\",\n",
    "        \"我常担心有什么不好的事情要发生\",\n",
    "        \"我很少感到忧郁或沮丧\"  # 反向计分\n",
    "    ],\n",
    "    \"严谨性\": [\n",
    "        \"一旦确定了目标，我会坚持努力地实现它\",\n",
    "        \"我常常是仔细考虑之后才做出决定\",\n",
    "        \"别人认为我是个慎重的人\",\n",
    "        \"我喜欢一开头就把事情计划好\",\n",
    "        \"我工作或学习很勤奋\",\n",
    "        \"我是个倾尽全力做事的人\",\n",
    "        \"在工作上，我常只求能应付过去便可\",  # 反向计分\n",
    "        \"做事讲究逻辑和条理是我的一个特点\"\n",
    "    ],\n",
    "    \"宜人性\": [\n",
    "        \"我觉得大部分人基本上是心怀善意的\",\n",
    "        \"我不太关心别人是否受到不公正的待遇\",         # 反向计分\n",
    "        \"我时常觉得别人的痛苦与我无关\",            # 反向计分\n",
    "        \"我是那种只照顾好自己，不替别人担忧的人\",      # 反向计分\n",
    "        \"虽然社会上有些骗子，但我觉得大部分人还是可信的\",\n",
    "        \"当别人向我诉说不幸时，我常感到难过\",\n",
    "        \"尽管人类社会存在着一些阴暗的东西（如战争、罪恶、欺诈），我仍然相信人性总的来说是善良的\",\n",
    "        \"我常为那些遭遇不幸的人感到难过\"\n",
    "    ],\n",
    "    \"开放性\": [\n",
    "        \"我头脑中经常充满生动的画面\",\n",
    "        \"我是个勇于冒险，突破常规的人\",\n",
    "        \"我喜欢冒险\",\n",
    "        \"我对许多事情有着很强的好奇心\",\n",
    "        \"我身上具有别人没有的冒险精神\",\n",
    "        \"我渴望学习一些新东西，即使它们与我的日常生活无关\",\n",
    "        \"我的想象力相当丰富\",\n",
    "        \"我很愿意也很容易接受那些新事物、新观点、新想法\"\n",
    "    ],\n",
    "    \"外向性\": [\n",
    "        \"我对人多的聚会感到乏味\",           # 反向计分\n",
    "        \"在热闹的聚会上，我常常表现主动并尽情玩耍\",\n",
    "        \"我尽量避免参加人多的聚会和嘈杂的环境\",  # 反向计分\n",
    "        \"在一个团体中，我希望处于领导地位\",\n",
    "        \"我希望成为领导者而不是被领导者\",\n",
    "        \"别人多认为我是一个热情和友好的人\",\n",
    "        \"我喜欢参加社交与娱乐聚会\",\n",
    "        \"我希望成为领导者而不是被领导者\"\n",
    "    ]}\n",
    "reverse_items_personality = [\"我对人多的聚会感到乏味\",\n",
    "    \"我不太关心别人是否受到不公正的待遇\",\n",
    "    \"我时常觉得别人的痛苦与我无关\",\n",
    "    \"我尽量避免参加人多的聚会和嘈杂的环境\",\n",
    "    \"我是那种只照顾好自己，不替别人担忧的人\",\n",
    "    \"在工作上，我常只求能应付过去便可\",\n",
    "    \"我很少感到忧郁或沮丧\"]\n",
    "# 对反向题目进行 7-原分\n",
    "for col in reverse_items_personality:\n",
    "    if col in cbf_df_A.columns:\n",
    "        cbf_df_A[col] = 7 - cbf_df_A[col]\n",
    "# 各维度均值 & 归一化\n",
    "dims = [\"神经质\", \"严谨性\", \"宜人性\", \"开放性\", \"外向性\"]\n",
    "for dim, items in cbf_pi_b_columns.items():\n",
    "    cbf_df_A[dim] = cbf_df_A[items].mean(axis=1)\n",
    "for dim in dims:\n",
    "    cbf_df_A[dim] = (cbf_df_A[dim] - 1) / 5.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9855a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 2. 数据处理 —— 数据集 B（外部测试）\n",
    "#--------------------------------------------\n",
    "file_path_B = \"Data/Study2_data.csv\"\n",
    "df_B = pd.read_csv(file_path_B)\n",
    "cbf_df_B = df_B.copy()\n",
    "ratings_raw_B = df_B[rating_cols].values.astype(np.float32)\n",
    "ratings_converted_B = ratings_raw_B - 4.0\n",
    "# 反向计分\n",
    "for col in reverse_items_personality:\n",
    "    if col in cbf_df_B.columns:\n",
    "        cbf_df_B[col] = 7 - cbf_df_B[col]\n",
    "# 维度计算 & 归一化\n",
    "for dim, items in cbf_pi_b_columns.items():\n",
    "    cbf_df_B[dim] = cbf_df_B[items].mean(axis=1)\n",
    "for dim in dims:\n",
    "    cbf_df_B[dim] = (cbf_df_B[dim] - 1) / 5.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2330e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# 自动循环训练：mean, mean_std，full\n",
    "#------------------------------------------------------------------------\n",
    "#定义三种方式 - 统计特征函数：mean, mean_std，full\n",
    "def group_statistics(ratings, stat_type='mean'):\n",
    "    \"\"\"\n",
    "    ratings: ndarray, shape (n_samples, 25)\n",
    "    stat_type: 'sum', 'mean', or 'mean_std'\n",
    "    \"\"\"\n",
    "    group_indices = [list(range(i, i+5)) for i in range(0, 25, 5)]\n",
    "    features = []\n",
    "\n",
    "    for idx in group_indices:\n",
    "        group = ratings[:, idx]  \n",
    "        if stat_type == 'mean':\n",
    "            feat = np.mean(group, axis=1, keepdims=True)\n",
    "        elif stat_type == 'mean_std':\n",
    "            mean_ = np.mean(group, axis=1, keepdims=True)\n",
    "            std_  = np.std(group, axis=1, ddof=0, keepdims=True)\n",
    "            feat = np.concatenate([mean_, std_], axis=1)\n",
    "        elif stat_type == 'full':\n",
    "            feat = np.array([(group == b).sum(axis=1) / group.shape[1] for b in range(-3, 4)]).T\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown stat_type: {stat_type}\")\n",
    "        features.append(feat)\n",
    "    return np.concatenate(features, axis=1)\n",
    "\n",
    "feature_versions = {\n",
    "     'mean':     {'type': 'mean',     'input_dim': 5},\n",
    "     'mean_std': {'type': 'mean_std', 'input_dim': 10},\n",
    "    'full':     {'type': 'full',     'input_dim': 25}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ad88af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义逻辑回归类\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.where(x >= 0,\n",
    "                    1.0 / (1.0 + np.exp(-x)),\n",
    "                    np.exp(x) / (1.0 + np.exp(x)))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        # 初始化权重和偏置\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # 梯度下降\n",
    "        for _ in range(self.num_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = sigmoid(linear_model)\n",
    "\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / num_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_model)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}\n",
    "for v_name, cfg in feature_versions.items():##输入方式的循环###################################\n",
    "    \n",
    "    rf_results, gb_results, svr_results, log_results = {}, {}, {}, {}\n",
    "    ##数据的准备\n",
    "    X_A_feat = group_statistics(ratings_converted_A, stat_type=cfg['type']).astype(np.float32)\n",
    "    X_B_feat = group_statistics(ratings_converted_B, stat_type=cfg['type']).astype(np.float32)\n",
    "\n",
    "    preds_per_model = {\n",
    "        \"RandomForest\": {},\n",
    "        \"GradientBoosting\": {},\n",
    "        \"SVR\": {},\n",
    "        \"LogisticRegression\": {}\n",
    "    }\n",
    "\n",
    "    preds_per_model_B = {  # B 测试集预测\n",
    "        \"RandomForest\": {},\n",
    "        \"GradientBoosting\": {},\n",
    "        \"SVR\": {},\n",
    "        \"LogisticRegression\": {}\n",
    "    }\n",
    "    y_A_matrix = cbf_df_A[dims].values.astype(np.float32)  # shape = (n_subjects, n_dims)\n",
    "    num_subjects = X_A_feat.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    y_B_matrix = cbf_df_B[dims].values.astype(np.float32)  # shape = (n_subjects, n_dims)\n",
    "    num_subjects_B = X_B_feat.shape[0]\n",
    "\n",
    "\n",
    "    ##人格维度的循环##########################################################################\n",
    "    for dim in dims:\n",
    "        y_A = cbf_df_A[dim].values.astype(np.float32)\n",
    "        y_B = cbf_df_B[dim].values.astype(np.float32)\n",
    "\n",
    "        ## 引入10折交叉验证\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        ##折的循环############################################################################\n",
    "        val_preds_all_rf = [0] * len(X_A_feat)\n",
    "        val_preds_all_gb = [0] * len(X_A_feat)\n",
    "        val_preds_all_svr = [0] * len(X_A_feat)\n",
    "        val_preds_all_log = [0] * len(X_A_feat)\n",
    "        train_scores_rf, train_scores_gb, train_scores_svr, train_scores_log = [], [], [], []\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_A_feat)):\n",
    "            X_tr, X_val = X_A_feat[train_idx], X_A_feat[val_idx]\n",
    "            y_tr, y_val = y_A[train_idx], y_A[val_idx]\n",
    "\n",
    "\n",
    "            #随机森林回归——————————————————————————————————————————————————————————————————————————————\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=10,\n",
    "                max_depth=3,\n",
    "                random_state=42,\n",
    "                max_features=0.2, \n",
    "                n_jobs=-1,\n",
    "                min_samples_leaf = 10\n",
    "                )\n",
    "\n",
    "            rf_model.fit(X_tr, y_tr)\n",
    "            pred_train_rf = rf_model.predict(X_tr)\n",
    "            pred_val_rf = rf_model.predict(X_val)\n",
    "            \n",
    "            for idx, i in enumerate(val_idx):\n",
    "                val_preds_all_rf[i] = pred_val_rf[idx]\n",
    "            \n",
    "            # ---------- 每折内评估-------------------------\n",
    "            train_scores_rf.append([\n",
    "                np.sqrt(mean_squared_error(y_tr, pred_train_rf)),\n",
    "                np.corrcoef(y_tr, pred_train_rf)[0, 1]\n",
    "            ])\n",
    "           \n",
    "           \n",
    "            #梯度提升树模型————————————————————————————————————————————————————————————————————————————————————\n",
    "            gb_model = GradientBoostingRegressor(\n",
    "                n_estimators=80,  # 树的数量（100-200之间）\n",
    "                max_depth=3,    # 或设为适中值，如 5\n",
    "                max_features=0.1,  # 使用 60% 特征分裂\n",
    "                random_state=42,\n",
    "                learning_rate=0.01\n",
    "            )\n",
    "\n",
    "            gb_model.fit(X_tr, y_tr)\n",
    "            pred_val_gb = gb_model.predict(X_val)\n",
    "            pred_train_gb = gb_model.predict(X_tr)\n",
    "\n",
    "            for idx, i in enumerate(val_idx):\n",
    "                val_preds_all_gb[i] = pred_val_gb[idx]\n",
    "            \n",
    "            # ---------- 每折内评估-------------------------\n",
    "            train_preds_gb = rf_model.predict(X_tr)\n",
    "            rmse_train_gb = np.sqrt(mean_squared_error(y_tr, train_preds_gb))\n",
    "        \n",
    "            corr_train_gb = np.corrcoef(y_tr, train_preds_gb)[0, 1]\n",
    "           \n",
    "            train_scores_gb.append([\n",
    "                np.sqrt(mean_squared_error(y_tr, pred_train_gb)),\n",
    "                np.corrcoef(y_tr, pred_train_gb)[0, 1]\n",
    "            ])\n",
    "\n",
    "            #支持向量回归——————————————————————————————————————————————————————————————————————————————————————\n",
    "            svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)  \n",
    "            svr_model.fit(X_tr, y_tr)\n",
    "            \n",
    "            pred_val_svr = svr_model.predict(X_val)\n",
    "            pred_train_svr = svr_model.predict(X_tr)\n",
    "\n",
    "            for idx, i in enumerate(val_idx):\n",
    "                val_preds_all_svr[i] = pred_val_svr[idx]\n",
    "            \n",
    "            # ---------- 每折内评估-------------------------\n",
    "            train_scores_svr.append([\n",
    "                np.sqrt(mean_squared_error(y_tr, pred_train_svr)),\n",
    "                np.corrcoef(y_tr, pred_train_svr)[0, 1]\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "            #逻辑回归——————————————————————————————————————————————————————————————————————————————————————————\n",
    "            log_model = LogisticRegression()\n",
    "            \n",
    "            log_model.fit(X_tr, y_tr) \n",
    "\n",
    "            pred_val_log = log_model.predict(X_val)\n",
    "            pred_train_log = log_model.predict(X_tr)\n",
    "\n",
    "            for idx, i in enumerate(val_idx):\n",
    "                val_preds_all_log[i] = pred_val_log[idx]\n",
    "                \n",
    "            # ---------- 每折内评估-------------------------\n",
    "            train_scores_log.append([\n",
    "                np.sqrt(mean_squared_error(y_tr, pred_train_log)),\n",
    "                np.corrcoef(y_tr, pred_train_log)[0, 1]\n",
    "            ])\n",
    "\n",
    "        #评估——————————————————————————————————————————————————————————————————————————————————————————————       \n",
    "        # ===================== 求训练集指标均值 =====================\n",
    "        train_rmse_rf, train_corr_rf = np.mean(train_scores_rf, axis=0)\n",
    "        train_rmse_gb, train_corr_gb = np.mean(train_scores_gb, axis=0)\n",
    "        train_rmse_svr, train_corr_svr = np.mean(train_scores_svr, axis=0)\n",
    "        train_rmse_log, train_corr_log = np.mean(train_scores_log, axis=0)\n",
    "       \n",
    "        #rf\n",
    "        rmse_v_rf = np.sqrt(mean_squared_error(y_A, val_preds_all_rf))\n",
    "        corr_v_rf = np.corrcoef(y_A, val_preds_all_rf)[0, 1]\n",
    "\n",
    "        #GBDT\n",
    "        rmse_v_gb = np.sqrt(mean_squared_error(y_A, val_preds_all_gb))\n",
    "        corr_v_gb = np.corrcoef(y_A, val_preds_all_gb)[0, 1]\n",
    "\n",
    "        #SVR\n",
    "        rmse_v_svr = np.sqrt(mean_squared_error(y_A, val_preds_all_svr))\n",
    "        corr_v_svr = np.corrcoef(y_A, val_preds_all_svr)[0, 1]\n",
    "\n",
    "        #logistic\n",
    "        rmse_v_log = np.sqrt(mean_squared_error(y_A, val_preds_all_log))\n",
    "        corr_v_log = np.corrcoef(y_A, val_preds_all_log)[0, 1]\n",
    "\n",
    "        # 训练A全集模型用于B测试（保证和原始一致，10折不影响B评估）#######################################################\n",
    "        #随机森林模型——————————————————————————————————————————————————————————————————————————————————————————\n",
    "\n",
    "        rf_model.fit(X_tr, y_tr)\n",
    "            \n",
    "        pred_B_rf = rf_model.predict(X_B_feat)\n",
    "\n",
    "        # 评估\n",
    "        mse_B_rf = mean_squared_error(y_B, pred_B_rf)\n",
    "        rmse_B_rf= np.sqrt(mse_B_rf)\n",
    "        corr_B_rf= np.corrcoef(y_B, pred_B_rf)[0,1]\n",
    "\n",
    "        #梯度提升树————————————————————————————————————————————————————————————————————————————————————————————\n",
    "\n",
    "        gb_model.fit(X_tr, y_tr)\n",
    "        \n",
    "        pred_B_gb = gb_model.predict(X_B_feat)\n",
    "\n",
    "        # 评估\n",
    "        mse_B_gb = mean_squared_error(y_B, pred_B_gb)\n",
    "        rmse_B_gb= np.sqrt(mse_B_gb)\n",
    "        corr_B_gb= np.corrcoef(y_B, pred_B_gb)[0,1]\n",
    "        \n",
    "        #支持向量回归——————————————————————————————————————————————————————————————————————————————————————————\n",
    "        svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1) \n",
    "        svr_model.fit(X_A_feat, y_A)\n",
    "        pred_B_svr = svr_model.predict(X_B_feat)\n",
    "\n",
    "        #评估\n",
    "        rmse_B_svr = np.sqrt(mean_squared_error(y_B, pred_B_svr))\n",
    "        corr_B_svr = np.corrcoef(y_B, pred_B_svr)[0, 1]\n",
    "\n",
    "        #逻辑回归————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "        log_model = LogisticRegression(    )\n",
    "        log_model.fit(X_A_feat, y_A)\n",
    "        pred_B_log = log_model.predict(X_B_feat)\n",
    "        \n",
    "        #评估\n",
    "        mse_B_log = mean_squared_error(y_B, pred_B_log)\n",
    "        rmse_B_log = np.sqrt(mse_B_log)\n",
    "        corr_B_log = np.corrcoef(y_B, pred_B_log)[0, 1]\n",
    "\n",
    "\n",
    "        #结果记录####################################################################################################\n",
    "        rf_results[dim] = pd.Series({\n",
    "            'A_Train_RMSE': train_rmse_rf, 'A_Train_Corr': train_corr_rf,\n",
    "            'A_Val_RMSE': rmse_v_rf, 'A_Val_Corr': corr_v_rf,\n",
    "            'B_Test_RMSE': rmse_B_rf, 'B_Test_Corr': corr_B_rf\n",
    "        })\n",
    "\n",
    "        gb_results[dim] = pd.Series({\n",
    "            'A_Train_RMSE': train_rmse_gb, 'A_Train_Corr': train_corr_gb,\n",
    "            'A_Val_RMSE': rmse_v_gb,  'A_Val_Corr': corr_v_gb,\n",
    "            'B_Test_RMSE': rmse_B_gb,  'B_Test_Corr': corr_B_gb\n",
    "        })\n",
    "\n",
    "        svr_results[dim] = pd.Series({\n",
    "            'A_Train_RMSE': train_rmse_svr,  'A_Train_Corr': train_corr_svr,\n",
    "            'A_Val_RMSE': rmse_v_svr,  'A_Val_Corr': corr_v_svr,\n",
    "            'B_Test_RMSE': rmse_B_svr, 'B_Test_Corr': corr_B_svr\n",
    "        })\n",
    "\n",
    "        log_results[dim] = pd.Series({\n",
    "            'A_Train_RMSE': train_rmse_log, 'A_Train_Corr': train_corr_log,\n",
    "            'A_Val_RMSE': rmse_v_log, 'A_Val_Corr': corr_v_log,\n",
    "            'B_Test_RMSE': rmse_B_log,'B_Test_Corr': corr_B_log\n",
    "        })\n",
    "\n",
    "\n",
    "        preds_per_model[\"RandomForest\"][dim] = np.array(val_preds_all_rf)\n",
    "        preds_per_model[\"GradientBoosting\"][dim] = np.array(val_preds_all_gb)\n",
    "        preds_per_model[\"SVR\"][dim] = np.array(val_preds_all_svr)\n",
    "        preds_per_model[\"LogisticRegression\"][dim] = np.array(val_preds_all_log)\n",
    "\n",
    "        preds_per_model_B[\"RandomForest\"][dim] = pred_B_rf\n",
    "        preds_per_model_B[\"GradientBoosting\"][dim] = pred_B_gb\n",
    "        preds_per_model_B[\"SVR\"][dim] = pred_B_svr\n",
    "        preds_per_model_B[\"LogisticRegression\"][dim] = pred_B_log\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    records = []\n",
    "    for subj_idx in range(num_subjects):\n",
    "        subj_name = f\"subj_{subj_idx+1}\"\n",
    "        for dim_idx, dim in enumerate(dims):\n",
    "            rf_err = abs(preds_per_model[\"RandomForest\"][dim][subj_idx] - y_A_matrix[subj_idx, dim_idx])\n",
    "            gb_err = abs(preds_per_model[\"GradientBoosting\"][dim][subj_idx] - y_A_matrix[subj_idx, dim_idx])\n",
    "            svr_err = abs(preds_per_model[\"SVR\"][dim][subj_idx] - y_A_matrix[subj_idx, dim_idx])\n",
    "            log_err = abs(preds_per_model[\"LogisticRegression\"][dim][subj_idx] - y_A_matrix[subj_idx, dim_idx])\n",
    "            records.append([subj_name, dim, rf_err, gb_err, svr_err, log_err])\n",
    "\n",
    "    df_model_errors = pd.DataFrame(\n",
    "        records,\n",
    "        columns=[\"subject_id\", \"trait\",\n",
    "                 f\"{v_name}_RandomForest\",\n",
    "                 f\"{v_name}_GradientBoosting\",\n",
    "                 f\"{v_name}_SVR\",\n",
    "                 f\"{v_name}_LogisticRegression\"]\n",
    "    )\n",
    "\n",
    "    wide_path = r\"Detailed_Output/A_wide_abs_errors_model1.csv\"\n",
    "    wide_df = pd.read_csv(wide_path, encoding=\"utf-8-sig\")\n",
    "    merged = wide_df.merge(df_model_errors, on=[\"subject_id\", \"trait\"], how=\"left\")\n",
    "\n",
    "    save_path = r\"Detailed_Output\\A_wide_abs_errors_final.csv\"\n",
    "    merged.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "#改动开始\n",
    "    # ---------------- B 宽表 ----------------\n",
    "    records_B = []\n",
    "    for subj_idx in range(num_subjects_B):\n",
    "        subj_name = f\"subj_{subj_idx+1}\"\n",
    "        for dim_idx, dim in enumerate(dims):\n",
    "            rf_err = abs(preds_per_model_B[\"RandomForest\"][dim][subj_idx] - y_B_matrix[subj_idx, dim_idx])\n",
    "            gb_err = abs(preds_per_model_B[\"GradientBoosting\"][dim][subj_idx] - y_B_matrix[subj_idx, dim_idx])\n",
    "            svr_err = abs(preds_per_model_B[\"SVR\"][dim][subj_idx] - y_B_matrix[subj_idx, dim_idx])\n",
    "            log_err = abs(preds_per_model_B[\"LogisticRegression\"][dim][subj_idx] - y_B_matrix[subj_idx, dim_idx])\n",
    "            records_B.append([subj_name, dim, rf_err, gb_err, svr_err, log_err])\n",
    "    df_model_errors_B = pd.DataFrame(records_B,\n",
    "        columns=[\"subject_id\",\"trait\",\n",
    "                 f\"{v_name}_RandomForest\",f\"{v_name}_GradientBoosting\",\n",
    "                 f\"{v_name}_SVR\",f\"{v_name}_LogisticRegression\"])\n",
    "    wide_path_B = r\"Detailed_Output\\B_wide_abs_errors_final.csv\"\n",
    "    if os.path.exists(wide_path_B):\n",
    "        wide_df_B = pd.read_csv(wide_path_B, encoding=\"utf-8-sig\")\n",
    "        merged_B = wide_df_B.merge(df_model_errors_B, on=[\"subject_id\", \"trait\"], how=\"left\")\n",
    "    else:\n",
    "        merged_B = df_model_errors_B\n",
    "    merged_B.to_csv(wide_path_B, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "\n",
    "    final_results[v_name] = {\n",
    "        \"RandomForest\": pd.DataFrame(rf_results).T,\n",
    "        \"GradientBoosting\": pd.DataFrame(gb_results).T,\n",
    "        \"SVR\": pd.DataFrame(svr_results).T,\n",
    "        \"LogisticRegression\": pd.DataFrame(log_results).T\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988297b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': {'RandomForest':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.178616      0.421967    0.184364    0.318193     0.209520   \n",
      "严谨性      0.099468      0.393154    0.103465    0.239436     0.110432   \n",
      "宜人性      0.111177      0.405119    0.116479    0.253538     0.133345   \n",
      "开放性      0.133575      0.451312    0.139699    0.325359     0.166164   \n",
      "外向性      0.180080      0.472981    0.186713    0.369907     0.211085   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.301794  \n",
      "严谨性     0.426626  \n",
      "宜人性     0.346291  \n",
      "开放性     0.385376  \n",
      "外向性     0.363727  , 'GradientBoosting':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.179414      0.527049    0.186271    0.330094     0.207013   \n",
      "严谨性      0.099526      0.533767    0.104354    0.221706     0.113737   \n",
      "宜人性      0.111779      0.511210    0.117226    0.246791     0.134490   \n",
      "开放性      0.134373      0.535066    0.140022    0.358331     0.168500   \n",
      "外向性      0.180859      0.566561    0.188182    0.403988     0.212404   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.394823  \n",
      "严谨性     0.350575  \n",
      "宜人性     0.346508  \n",
      "开放性     0.428252  \n",
      "外向性     0.425855  , 'SVR':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.164274      0.549643    0.189926    0.265711     0.211984   \n",
      "严谨性      0.091914      0.513801    0.108977    0.156220     0.115171   \n",
      "宜人性      0.103835      0.507083    0.120420    0.226310     0.131705   \n",
      "开放性      0.122992      0.563372    0.141046    0.325479     0.177557   \n",
      "外向性      0.165367      0.573040    0.195267    0.293854     0.222095   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.410734  \n",
      "严谨性     0.236046  \n",
      "宜人性     0.354618  \n",
      "开放性     0.245631  \n",
      "外向性     0.356236  , 'LogisticRegression':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.187492      0.284095    0.189657    0.257009     0.204079   \n",
      "严谨性      0.111790      0.294786    0.113341    0.281091     0.144347   \n",
      "宜人性      0.121120      0.307429    0.122749    0.289745     0.159029   \n",
      "开放性      0.143142      0.325406    0.144807    0.306763     0.164761   \n",
      "外向性      0.184970      0.389235    0.186698    0.371349     0.199552   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.326447  \n",
      "严谨性     0.322397  \n",
      "宜人性     0.274184  \n",
      "开放性     0.411579  \n",
      "外向性     0.444970  }, 'mean_std': {'RandomForest':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.175852      0.460199    0.187072    0.266398     0.207905   \n",
      "严谨性      0.097208      0.459447    0.102744    0.266728     0.115852   \n",
      "宜人性      0.109306      0.457834    0.116926    0.239017     0.135760   \n",
      "开放性      0.131159      0.489898    0.139115    0.336736     0.163366   \n",
      "外向性      0.177270      0.500348    0.189769    0.319370     0.204008   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.317094  \n",
      "严谨性     0.178671  \n",
      "宜人性     0.254966  \n",
      "开放性     0.414315  \n",
      "外向性     0.442137  , 'GradientBoosting':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.179538      0.570145    0.188286    0.286944     0.209443   \n",
      "严谨性      0.099063      0.600227    0.104307    0.244453     0.116122   \n",
      "宜人性      0.111916      0.566396    0.117852    0.229389     0.136664   \n",
      "开放性      0.134849      0.578019    0.141002    0.359907     0.169369   \n",
      "外向性      0.182934      0.595523    0.190929    0.375825     0.214937   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.387704  \n",
      "严谨性     0.201139  \n",
      "宜人性     0.311421  \n",
      "开放性     0.405230  \n",
      "外向性     0.404312  , 'SVR':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.148472      0.671901    0.195084    0.213600     0.202726   \n",
      "严谨性      0.083551      0.639757    0.106382    0.240485     0.116517   \n",
      "宜人性      0.093945      0.646405    0.121914    0.213631     0.142118   \n",
      "开放性      0.111971      0.676065    0.148149    0.243104     0.160684   \n",
      "外向性      0.145757      0.700049    0.199591    0.268878     0.212239   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.447844  \n",
      "严谨性     0.273861  \n",
      "宜人性     0.204328  \n",
      "开放性     0.433078  \n",
      "外向性     0.375238  , 'LogisticRegression':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.187450      0.269886    0.190171    0.230699     0.204707   \n",
      "严谨性      0.103078      0.313522    0.104543    0.289959     0.113413   \n",
      "宜人性      0.114596      0.333420    0.116555    0.302190     0.139494   \n",
      "开放性      0.137215      0.376180    0.139009    0.351778     0.159142   \n",
      "外向性      0.180951      0.427819    0.183220    0.403246     0.199753   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.304744  \n",
      "严谨性     0.404064  \n",
      "宜人性     0.314643  \n",
      "开放性     0.432329  \n",
      "外向性     0.453421  }, 'full': {'RandomForest':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.175820      0.477182    0.187717    0.254021     0.210214   \n",
      "严谨性      0.098844      0.435346    0.104485    0.197401     0.111386   \n",
      "宜人性      0.108296      0.478072    0.116051    0.266257     0.136055   \n",
      "开放性      0.130619      0.499792    0.137334    0.373896     0.166005   \n",
      "外向性      0.175705      0.520635    0.185078    0.388251     0.210526   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.276246  \n",
      "严谨性     0.366216  \n",
      "宜人性     0.251206  \n",
      "开放性     0.369659  \n",
      "外向性     0.402953  , 'GradientBoosting':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.179501      0.597379    0.188529    0.288201     0.208979   \n",
      "严谨性      0.099434      0.635809    0.105159    0.184621     0.114265   \n",
      "宜人性      0.110868      0.599066    0.116040    0.331340     0.136629   \n",
      "开放性      0.134199      0.606891    0.139927    0.411044     0.169101   \n",
      "外向性      0.182539      0.609952    0.191406    0.367186     0.215019   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.458950  \n",
      "严谨性     0.340848  \n",
      "宜人性     0.299274  \n",
      "开放性     0.424012  \n",
      "外向性     0.451727  , 'SVR':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.100269      0.901107    0.193594    0.265577     0.203543   \n",
      "严谨性      0.075147      0.754019    0.109894    0.177536     0.107464   \n",
      "宜人性      0.080170      0.779994    0.125619    0.169677     0.138926   \n",
      "开放性      0.085009      0.850158    0.152178    0.214033     0.162340   \n",
      "外向性      0.097280      0.907212    0.199713    0.279388     0.210362   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.397959  \n",
      "严谨性     0.417630  \n",
      "宜人性     0.241418  \n",
      "开放性     0.394729  \n",
      "外向性     0.383120  , 'LogisticRegression':      A_Train_RMSE  A_Train_Corr  A_Val_RMSE  A_Val_Corr  B_Test_RMSE  \\\n",
      "神经质      0.187529      0.320343    0.188932    0.269447     0.208881   \n",
      "严谨性      0.105063      0.181957    0.105684    0.146884     0.113528   \n",
      "宜人性      0.116905      0.262500    0.117973    0.211256     0.136792   \n",
      "开放性      0.140280      0.371574    0.141468    0.330343     0.168057   \n",
      "外向性      0.190634      0.385491    0.192055    0.343576     0.215643   \n",
      "\n",
      "     B_Test_Corr  \n",
      "神经质     0.362039  \n",
      "严谨性     0.278842  \n",
      "宜人性     0.240578  \n",
      "开放性     0.410964  \n",
      "外向性     0.392760  }}\n"
     ]
    }
   ],
   "source": [
    "output_path = r\"Main_Result/Machine_Learning.txt\"\n",
    "print(final_results)\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for v_name, models_result in final_results.items():\n",
    "        f.write(f\"\\n================ 特征版本: {v_name} ================\\n\\n\")\n",
    "        for model_name, df in models_result.items():\n",
    "            f.write(f\"--- 模型: {model_name} ---\\n\")\n",
    "            f.write(df.round(4).to_string())\n",
    "            f.write(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
